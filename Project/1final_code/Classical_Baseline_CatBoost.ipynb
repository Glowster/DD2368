{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Baseline: CatBoost\n",
    "\n",
    "**Classical machine learning baseline using CatBoost gradient boosting for comparison with quantum models.**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "import time\n",
    "\n",
    "SEED = 123\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(\"Imports loaded successfully!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Download and load dataset\n",
    "path = kagglehub.dataset_download(\"sameepvani/nasa-nearest-earth-objects\")\n",
    "df = pd.read_csv(f\"{path}/neo.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features = ['est_diameter_min', 'est_diameter_max', 'relative_velocity', 'miss_distance', 'absolute_magnitude']\n",
    "target = 'hazardous'\n",
    "\n",
    "print(f\"Features: {features}\")\n",
    "print(f\"Target: {target}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create balanced dataset\n",
    "N = 8840\n",
    "np.random.seed(SEED)\n",
    "\n",
    "df_true = df[df[target] == True]\n",
    "df_false = df[df[target] == False]\n",
    "\n",
    "df_subset_true = df_true.iloc[np.random.choice(df_true.shape[0], size=N, replace=False)]\n",
    "df_subset_false = df_false.iloc[np.random.choice(df_false.shape[0], size=N, replace=False)]\n",
    "\n",
    "df_subset = pd.concat([df_subset_true, df_subset_false])\n",
    "\n",
    "print(f\"Balanced dataset shape: {df_subset.shape}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(df_subset[target].value_counts())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Split into train (80%) and test (20%)\n",
    "train_df, test_df = train_test_split(\n",
    "    df_subset,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=df_subset[target]\n",
    ")\n",
    "\n",
    "# Further split train into train (80%) and validation (20%)\n",
    "train_split_df, val_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df[target]\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {train_split_df.shape}\")\n",
    "print(f\"Validation shape: {val_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract features and labels\n",
    "X_train = train_split_df[features].to_numpy()\n",
    "Y_train = train_split_df[target].apply(lambda x: int(x)).to_numpy()\n",
    "\n",
    "X_val = val_df[features].to_numpy()\n",
    "Y_val = val_df[target].apply(lambda x: int(x)).to_numpy()\n",
    "\n",
    "X_test = test_df[features].to_numpy()\n",
    "Y_test = test_df[target].apply(lambda x: int(x)).to_numpy()\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_val shape: {X_val_scaled.shape}\")\n",
    "print(f\"X_test shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\nClass balance in training set:\")\n",
    "print(f\"  Class 0: {(Y_train == 0).sum()}\")\n",
    "print(f\"  Class 1: {(Y_train == 1).sum()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# CATBOOST CLASSIFIER\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Training CatBoost Classifier\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create CatBoost classifier\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.1,\n",
    "    depth=4,\n",
    "    verbose=False,\n",
    "    random_seed=SEED\n",
    ")\n",
    "\n",
    "# Train on scaled data\n",
    "start_time = time.time()\n",
    "catboost_model.fit(X_train_scaled, Y_train, eval_set=(X_val_scaled, Y_val))\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining completed in {train_time:.2f}s\")\n",
    "\n",
    "# Validation predictions\n",
    "val_pred_class = catboost_model.predict(X_val_scaled)\n",
    "val_pred_proba = catboost_model.predict_proba(X_val_scaled)[:, 1]\n",
    "val_accuracy = accuracy_score(Y_val, val_pred_class)\n",
    "val_roc_auc = roc_auc_score(Y_val, val_pred_proba)\n",
    "\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"  ROC-AUC: {val_roc_auc:.4f}\")\n",
    "\n",
    "# Test predictions\n",
    "test_pred_class = catboost_model.predict(X_test_scaled)\n",
    "test_pred_proba = catboost_model.predict_proba(X_test_scaled)[:, 1]\n",
    "test_accuracy = accuracy_score(Y_test, test_pred_class)\n",
    "test_roc_auc = roc_auc_score(Y_test, test_pred_proba)\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"  ROC-AUC: {test_roc_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# DETAILED EVALUATION\n",
    "# ============================================\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(Y_test, test_pred_class)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print()\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, test_pred_class))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_xlabel('Predicted', fontsize=12)\n",
    "axes[0].set_ylabel('True', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, test_pred_proba)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {test_roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower right\", fontsize=10)\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('catboost_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# FEATURE IMPORTANCE\n",
    "# ============================================\n",
    "\n",
    "feature_importance = catboost_model.get_feature_importance()\n",
    "feature_names = features\n",
    "\n",
    "# Create DataFrame for feature importance\n",
    "fi_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(fi_df)\n",
    "print()\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(fi_df['Feature'], fi_df['Importance'], color='steelblue', edgecolor='navy')\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('CatBoost Feature Importance', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('catboost_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================\n",
    "# SUMMARY\n",
    "# ============================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CATBOOST CLASSICAL BASELINE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  Iterations: 100\")\n",
    "print(f\"  Learning Rate: 0.1\")\n",
    "print(f\"  Depth: 4\")\n",
    "print(f\"  Features: {len(features)}\")\n",
    "print(f\"\\nDataset:\")\n",
    "print(f\"  Training samples: {len(X_train_scaled)}\")\n",
    "print(f\"  Validation samples: {len(X_val_scaled)}\")\n",
    "print(f\"  Test samples: {len(X_test_scaled)}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"  Validation ROC-AUC: {val_roc_auc:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"  Test ROC-AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"  Training Time: {train_time:.2f}s\")\n",
    "print(f\"\\n{'='*60}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}